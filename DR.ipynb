{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anshikaa1212/DeDues/blob/main/DR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "1Kby-ljA0Lmp"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGvVN5uE0T3I"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ow-2J0PPv9lk"
      },
      "outputs": [],
      "source": [
        "#importing all te req lib\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras import backend as K\n",
        "from keras.preprocessing import image\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEdqN8dfwJai"
      },
      "outputs": [],
      "source": [
        "# dimensions of our images.\n",
        "img_width, img_height = 299, 299\n",
        "\n",
        "#defining the data directories\n",
        "train_data_dir= '/content/drive/MyDrive/DataSet/data/data/train'\n",
        "validation_data_dir= '/content/drive/MyDrive/DataSet/data/data/validation'\n",
        "n_training_sample= 190\n",
        "n_validation_sample= 37\n",
        "epochs=40\n",
        "batch_size=8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bpuu6QFEwOZG"
      },
      "outputs": [],
      "source": [
        "if K.image_data_format() == 'channels_first':\n",
        "    input_shape = (3, img_width, img_height)\n",
        "else:\n",
        "    input_shape = (img_width, img_height, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSW2kztCwQM4"
      },
      "outputs": [],
      "source": [
        "#defining the model\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Conv2D(128, (3,3), activation='relu', input_shape=input_shape),\n",
        "                                    tf.keras.layers.MaxPooling2D(2,2),\n",
        "                                    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),#added layer\n",
        "                                    tf.keras.layers.MaxPooling2D(2,2),\n",
        "                                    tf.keras.layers.Flatten(), \n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu), \n",
        "                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(1, activation=tf.nn.softmax)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8dR-8CDFObAs"
      },
      "outputs": [],
      "source": [
        "#defining the optimizer and metrics\n",
        "model.compile(optimizer = tf.optimizers.Adam(),\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fX_TU09OhDf",
        "outputId": "768e5bd5-1286-4d59-89c7-7c1727014c91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_9 (Conv2D)           (None, 297, 297, 128)     3584      \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 148, 148, 128)    0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 146, 146, 64)      73792     \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 73, 73, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 341056)            0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 128)               43655296  \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 43,740,993\n",
            "Trainable params: 43,740,993\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uf8P7lQvPAyM",
        "outputId": "01946809-3a2d-4124-917a-83472de1910d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 984 images belonging to 2 classes.\n",
            "Found 328 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# this is the augmentation configuration we will use for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "# this is the augmentation configuration we will use for testing:\n",
        "# only rescaling\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOKtz3uWPeFl",
        "outputId": "4c2014b4-af59-4041-8674-f32a7e8f4fbc"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "23/23 [==============================] - 72s 3s/step - loss: 0.0000e+00 - accuracy: 0.4620 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 2/40\n",
            "23/23 [==============================] - 71s 3s/step - loss: 0.0000e+00 - accuracy: 0.4674 - val_loss: 0.0000e+00 - val_accuracy: 0.5312\n",
            "Epoch 3/40\n",
            "23/23 [==============================] - 75s 3s/step - loss: 0.0000e+00 - accuracy: 0.4891 - val_loss: 0.0000e+00 - val_accuracy: 0.5938\n",
            "Epoch 4/40\n",
            "23/23 [==============================] - 70s 3s/step - loss: 0.0000e+00 - accuracy: 0.4728 - val_loss: 0.0000e+00 - val_accuracy: 0.3438\n",
            "Epoch 5/40\n",
            "23/23 [==============================] - 70s 3s/step - loss: 0.0000e+00 - accuracy: 0.4728 - val_loss: 0.0000e+00 - val_accuracy: 0.6875\n",
            "Epoch 6/40\n",
            "23/23 [==============================] - 70s 3s/step - loss: 0.0000e+00 - accuracy: 0.4674 - val_loss: 0.0000e+00 - val_accuracy: 0.5625\n",
            "Epoch 7/40\n",
            "23/23 [==============================] - 71s 3s/step - loss: 0.0000e+00 - accuracy: 0.4348 - val_loss: 0.0000e+00 - val_accuracy: 0.3438\n",
            "Epoch 8/40\n",
            "23/23 [==============================] - 69s 3s/step - loss: 0.0000e+00 - accuracy: 0.4620 - val_loss: 0.0000e+00 - val_accuracy: 0.6250\n",
            "Epoch 9/40\n",
            "23/23 [==============================] - 69s 3s/step - loss: 0.0000e+00 - accuracy: 0.5272 - val_loss: 0.0000e+00 - val_accuracy: 0.5312\n",
            "Epoch 10/40\n",
            "23/23 [==============================] - 69s 3s/step - loss: 0.0000e+00 - accuracy: 0.5924 - val_loss: 0.0000e+00 - val_accuracy: 0.4688\n",
            "Epoch 11/40\n",
            "23/23 [==============================] - 70s 3s/step - loss: 0.0000e+00 - accuracy: 0.5543 - val_loss: 0.0000e+00 - val_accuracy: 0.4375\n",
            "Epoch 12/40\n",
            "23/23 [==============================] - 69s 3s/step - loss: 0.0000e+00 - accuracy: 0.5000 - val_loss: 0.0000e+00 - val_accuracy: 0.3750\n",
            "Epoch 13/40\n",
            "23/23 [==============================] - 69s 3s/step - loss: 0.0000e+00 - accuracy: 0.4620 - val_loss: 0.0000e+00 - val_accuracy: 0.3750\n",
            "Epoch 14/40\n",
            "23/23 [==============================] - 69s 3s/step - loss: 0.0000e+00 - accuracy: 0.5598 - val_loss: 0.0000e+00 - val_accuracy: 0.4375\n",
            "Epoch 15/40\n",
            "23/23 [==============================] - 69s 3s/step - loss: 0.0000e+00 - accuracy: 0.5163 - val_loss: 0.0000e+00 - val_accuracy: 0.6250\n",
            "Epoch 16/40\n",
            "23/23 [==============================] - 69s 3s/step - loss: 0.0000e+00 - accuracy: 0.5109 - val_loss: 0.0000e+00 - val_accuracy: 0.6875\n",
            "Epoch 17/40\n",
            "23/23 [==============================] - 69s 3s/step - loss: 0.0000e+00 - accuracy: 0.4674 - val_loss: 0.0000e+00 - val_accuracy: 0.4375\n",
            "Epoch 18/40\n",
            "23/23 [==============================] - 69s 3s/step - loss: 0.0000e+00 - accuracy: 0.5815 - val_loss: 0.0000e+00 - val_accuracy: 0.4062\n",
            "Epoch 19/40\n",
            "23/23 [==============================] - 69s 3s/step - loss: 0.0000e+00 - accuracy: 0.4402 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 20/40\n",
            "23/23 [==============================] - 69s 3s/step - loss: 0.0000e+00 - accuracy: 0.4674 - val_loss: 0.0000e+00 - val_accuracy: 0.4375\n",
            "Epoch 21/40\n",
            "23/23 [==============================] - 69s 3s/step - loss: 0.0000e+00 - accuracy: 0.4837 - val_loss: 0.0000e+00 - val_accuracy: 0.5312\n",
            "Epoch 22/40\n",
            "23/23 [==============================] - 69s 3s/step - loss: 0.0000e+00 - accuracy: 0.5054 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 23/40\n",
            "23/23 [==============================] - 69s 3s/step - loss: 0.0000e+00 - accuracy: 0.5380 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 24/40\n",
            "23/23 [==============================] - 69s 3s/step - loss: 0.0000e+00 - accuracy: 0.5163 - val_loss: 0.0000e+00 - val_accuracy: 0.4688\n",
            "Epoch 25/40\n",
            "23/23 [==============================] - 69s 3s/step - loss: 0.0000e+00 - accuracy: 0.4837 - val_loss: 0.0000e+00 - val_accuracy: 0.7188\n",
            "Epoch 26/40\n",
            "23/23 [==============================] - 69s 3s/step - loss: 0.0000e+00 - accuracy: 0.5000 - val_loss: 0.0000e+00 - val_accuracy: 0.6562\n",
            "Epoch 27/40\n",
            "23/23 [==============================] - 69s 3s/step - loss: 0.0000e+00 - accuracy: 0.5272 - val_loss: 0.0000e+00 - val_accuracy: 0.4375\n",
            "Epoch 28/40\n",
            "23/23 [==============================] - 69s 3s/step - loss: 0.0000e+00 - accuracy: 0.5707 - val_loss: 0.0000e+00 - val_accuracy: 0.5938\n",
            "Epoch 29/40\n",
            "23/23 [==============================] - 69s 3s/step - loss: 0.0000e+00 - accuracy: 0.5272 - val_loss: 0.0000e+00 - val_accuracy: 0.4688\n",
            "Epoch 30/40\n",
            "23/23 [==============================] - 69s 3s/step - loss: 0.0000e+00 - accuracy: 0.4946 - val_loss: 0.0000e+00 - val_accuracy: 0.4688\n",
            "Epoch 31/40\n",
            "23/23 [==============================] - 69s 3s/step - loss: 0.0000e+00 - accuracy: 0.4891 - val_loss: 0.0000e+00 - val_accuracy: 0.5938\n",
            "Epoch 32/40\n",
            "23/23 [==============================] - 69s 3s/step - loss: 0.0000e+00 - accuracy: 0.5326 - val_loss: 0.0000e+00 - val_accuracy: 0.5000\n",
            "Epoch 33/40\n",
            "23/23 [==============================] - 69s 3s/step - loss: 0.0000e+00 - accuracy: 0.5272 - val_loss: 0.0000e+00 - val_accuracy: 0.5625\n",
            "Epoch 34/40\n",
            "23/23 [==============================] - 69s 3s/step - loss: 0.0000e+00 - accuracy: 0.5000 - val_loss: 0.0000e+00 - val_accuracy: 0.6875\n",
            "Epoch 35/40\n",
            "23/23 [==============================] - 69s 3s/step - loss: 0.0000e+00 - accuracy: 0.5272 - val_loss: 0.0000e+00 - val_accuracy: 0.5625\n",
            "Epoch 36/40\n",
            "23/23 [==============================] - 69s 3s/step - loss: 0.0000e+00 - accuracy: 0.4728 - val_loss: 0.0000e+00 - val_accuracy: 0.3438\n",
            "Epoch 37/40\n",
            "23/23 [==============================] - 69s 3s/step - loss: 0.0000e+00 - accuracy: 0.4783 - val_loss: 0.0000e+00 - val_accuracy: 0.4375\n",
            "Epoch 38/40\n",
            "23/23 [==============================] - 69s 3s/step - loss: 0.0000e+00 - accuracy: 0.5543 - val_loss: 0.0000e+00 - val_accuracy: 0.4688\n",
            "Epoch 39/40\n",
            "23/23 [==============================] - 69s 3s/step - loss: 0.0000e+00 - accuracy: 0.4783 - val_loss: 0.0000e+00 - val_accuracy: 0.6875\n",
            "Epoch 40/40\n",
            "23/23 [==============================] - 69s 3s/step - loss: 0.0000e+00 - accuracy: 0.4946 - val_loss: 0.0000e+00 - val_accuracy: 0.4375\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6afaae7c90>"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ],
      "source": [
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=n_training_sample // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=n_validation_sample // batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "A0im_oTqO7RX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54981b78-3ee6-4c08-d33d-4c84beace6fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.]]\n"
          ]
        }
      ],
      "source": [
        "#testing the model\n",
        "pred= image.load_img('/content/drive/MyDrive/DataSet/data/data/test/pm2.jpg', target_size=(299,299))\n",
        "pred=image.img_to_array(pred)\n",
        "pred= np.expand_dims(pred, axis=0)\n",
        "result= model.predict(pred)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIaaq4z4MJIG",
        "outputId": "910ac7c7-279a-4472-af32-77936292d62a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The fruit in the image is Apple\n"
          ]
        }
      ],
      "source": [
        "if result[0][0]==1:\n",
        "    answer='Apple'\n",
        "else:\n",
        "    answer='Pomegranate'\n",
        "print(\"The fruit in the image is\",answer)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "DR.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNzqpQHzx2ATYtH7hixIew2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}